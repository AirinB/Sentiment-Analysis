{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "later-couple",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "religious-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-pharmaceutical",
   "metadata": {},
   "source": [
    "## Preparing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "champion-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./archive/Train.csv')\n",
    "test_data = pd.read_csv('./archive/Test.csv')\n",
    "validation_data = pd.read_csv('./archive/Valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "beneficial-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 40000\n",
      "5000 5000\n",
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "x_tr, y_tr = train_data['text'].values.astype(str), train_data['label'].values\n",
    "x_val, y_val = validation_data['text'].values.astype(str), validation_data['label'].values\n",
    "x_test,y_test = test_data['text'].values.astype(str) , test_data['label'].values\n",
    "print(len(x_tr), len(y_tr))\n",
    "print(len(x_val), len(y_val))\n",
    "print(len(x_test), len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "expressed-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "tight-compound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 40000\n",
      "5000 5000\n",
      "5000 5000\n",
      "40000 40000\n",
      "5000 5000\n",
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the sentences\n",
    "from string import punctuation\n",
    "#convert all revies to lowercase\n",
    "x_tr = np.char.lower(x_tr)\n",
    "x_val = np.char.lower(x_val)\n",
    "x_test = np.char.lower(x_test)\n",
    "\n",
    "#remove punctuation\n",
    "x_tr= [c for c in x_tr if c not in punctuation]\n",
    "x_val = [c for c in x_val if c not in punctuation]\n",
    "x_test = [c for c in x_test if c not in punctuation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "egyptian-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 40000\n",
      "5000 5000\n",
      "5000 5000\n",
      "40000\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq  = tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "\n",
    "#padding to prepare sequences of same length\n",
    "x_tr_pad  = pad_sequences(x_tr_seq, maxlen=1000)\n",
    "x_val_pad = pad_sequences(x_val_seq, maxlen=1000)\n",
    "x_test_pad = pad_sequences(x_test_seq,maxlen=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accompanied-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of the reviews\n",
    "seqlen_train = [len(x) for x in x_tr_seq]\n",
    "seqlen_val = [len(x) for x in x_val_seq] \n",
    "seqlen_test = [len(x) for x in x_test_seq] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "complicated-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112204\n"
     ]
    }
   ],
   "source": [
    "# this might be an issue \n",
    "vocab=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elect-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "laden-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_file = \"glove.6B.100d.txt\"\n",
    "#embedding = gensim.models.KeyedVectors.load_word2vec_format(embedding_file, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-ghost",
   "metadata": {},
   "source": [
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "based-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.size() = torch.Size([40000, 1000]),\n",
      "y_train.size() = torch.Size([40000])\n",
      "seqlen_train.size() = torch.Size([40000])\n",
      "\n",
      "X_val.size() = torch.Size([5000, 1000]),\n",
      "y_val.size() = torch.Size([5000])\n",
      "seqlen_val.size() = torch.Size([5000])\n",
      "\n",
      "X_test.size() = torch.Size([5000, 1000]),\n",
      "y_test.size() = torch.Size([5000])\n",
      "seqlen_test.size() = torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(np.array(list(x_tr_pad)))\n",
    "y_train = torch.LongTensor(y_tr)\n",
    "seqlen_train = torch.LongTensor(seqlen_train)\n",
    "print(f\"{X_train.size() = },\\n{y_train.size() = }\\n{seqlen_train.size() = }\\n\")\n",
    "\n",
    "X_val = torch.from_numpy(np.array(list(x_val_pad)))\n",
    "y_val = torch.LongTensor(y_val)\n",
    "seqlen_val = torch.LongTensor(seqlen_val)\n",
    "print(f\"{X_val.size() = },\\n{y_val.size() = }\\n{seqlen_val.size() = }\\n\")\n",
    "\n",
    "\n",
    "X_test = torch.from_numpy(np.array(list(x_test_pad)))\n",
    "y_test = torch.LongTensor(y_test)\n",
    "seqlen_test = torch.LongTensor(seqlen_test)\n",
    "print(f\"{X_test.size() = },\\n{y_test.size() = }\\n{seqlen_test.size() = }\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-principal",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "apart-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dense = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "    # the input signature of forward changes\n",
    "    def forward(self, sequences, sequence_lens):\n",
    "        embedded = self.embedding(sequences)\n",
    "        \n",
    "        # THIS IS THE MODIFIED PART\n",
    "        # returns a PackedSequence object\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded,\n",
    "            sequence_lens,\n",
    "            enforce_sorted=False,\n",
    "            batch_first=True)\n",
    "        packed_outputs, (h, c) = self.lstm(packed)\n",
    "        # extract LSTM outputs (not used here)\n",
    "        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        h = torch.cat((h[0], h[1]), dim=-1)\n",
    "        output = self.dense(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-chain",
   "metadata": {},
   "source": [
    "## Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "sensitive-meditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(112204, 30)\n",
       "  (lstm): LSTM(30, 64, batch_first=True, bidirectional=True)\n",
       "  (dense): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = vocab\n",
    "embedding_size = 30\n",
    "hidden_size = 64\n",
    "# number of labels i.e 2\n",
    "output_size = train_data.label.nunique()\n",
    "\n",
    "model = LSTMClassifier(input_size, embedding_size, hidden_size, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-source",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "continent-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedIterator:\n",
    "    def __init__(self, *tensors, batch_size):\n",
    "        # all tensors must have the same first dimension\n",
    "        assert len(set(len(tensor) for tensor in tensors)) == 1\n",
    "        self.tensors = tensors\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def iterate_once(self):\n",
    "        num_data = len(self.tensors[0])\n",
    "        for start in range(0, num_data, self.batch_size):\n",
    "            end = start + self.batch_size\n",
    "            yield tuple(tensor[start:end] for tensor in self.tensors)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "rural-thompson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([501, 1000]), seqlens.size() = torch.Size([501]), y.size() = torch.Size([501])\n",
      "X.size() = torch.Size([421, 1000]), seqlens.size() = torch.Size([421]), y.size() = torch.Size([421])\n"
     ]
    }
   ],
   "source": [
    "train_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=501)\n",
    "#prints number of batches\n",
    "for X, seqlens, y in train_iter.iterate_once():\n",
    "    print(f\"{X.size() = }, {seqlens.size() = }, {y.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-edward",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "smart-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-wells",
   "metadata": {},
   "source": [
    "## Sanity check on Untrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "italian-european",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 12978176 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a1526d7af1c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqlen_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Train accuracy: {accuracy:.1%}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-b7601581dcf2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sequences, sequence_lens)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0menforce_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             batch_first=True)\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mpacked_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# extract LSTM outputs (not used here)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mlstm_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    663\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[0;32m    665\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0;32m    666\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 12978176 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "# requires a large memory as we have a large vocab\n",
    "logits = model(X_train, seqlen_train)\n",
    "y = logits.argmax(axis=1)\n",
    "accuracy = torch.sum(torch.eq(y, y_train)) / y.size(0)\n",
    "print(f\"Train accuracy: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "alternative-giant",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "start (1155502) + length (14) exceeds dimension size (1155502).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-3b4bfd681cba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqlen_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Dev accuracy: {accuracy:.1%}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-b7601581dcf2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sequences, sequence_lens)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0menforce_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             batch_first=True)\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mpacked_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# extract LSTM outputs (not used here)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mlstm_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    663\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[0;32m    665\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0;32m    666\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: start (1155502) + length (14) exceeds dimension size (1155502)."
     ]
    }
   ],
   "source": [
    "logits = model(X_val, seqlen_val)\n",
    "y = logits.argmax(axis=1)\n",
    "accuracy = torch.sum(torch.eq(y, y_val)) / y.size(0)\n",
    "print(f\"Dev accuracy: {accuracy:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
