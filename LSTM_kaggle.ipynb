{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"#### Preparing Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv\")\nvalidation_data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Valid.csv\")\n\ntrain_data.head()","metadata":{"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  I grew up (b. 1965) watching and loving the Th...      0\n1  When I put this movie in my DVD player, and sa...      0\n2  Why do people who do not know what a particula...      0\n3  Even though I have great interest in Biblical ...      0\n4  Im a die hard Dads Army fan and nothing will e...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I grew up (b. 1965) watching and loving the Th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I put this movie in my DVD player, and sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do people who do not know what a particula...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even though I have great interest in Biblical ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Im a die hard Dads Army fan and nothing will e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Downsampling\n\nWe don't need much data to train the model, let's downsample it and train on a small subset.","metadata":{}},{"cell_type":"code","source":"train_data = train_data.sample(1000, random_state=1).reset_index(drop=True)\ntest_data = test_data.sample(200, random_state=1).reset_index(drop=True)\nvalidation_data = validation_data.sample(200, random_state=1).reset_index(drop=True)\ntrain_data.head()","metadata":{"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  I was reviewing some old VHS tapes I have and ...      1\n1  I never really knew who Robert Wuhl was before...      1\n2  This movie grabbed me with the incredible open...      1\n3  Lame, cliched superhero action movie drivel. I...      0\n4  Little did I know that when I signed up the th...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I was reviewing some old VHS tapes I have and ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I never really knew who Robert Wuhl was before...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This movie grabbed me with the incredible open...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lame, cliched superhero action movie drivel. I...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Little did I know that when I signed up the th...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_tr, y_tr = train_data['text'].values.astype(str), train_data['label'].values\nx_val, y_val = validation_data['text'].values.astype(str), validation_data['label'].values\nx_test,y_test = test_data['text'].values.astype(str) , test_data['label'].values\nprint(len(x_tr), len(y_tr))\nprint(len(x_val), len(y_val))\nprint(len(x_test), len(y_test))","metadata":{"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"1000 1000\n200 200\n200 200\n","output_type":"stream"}]},{"cell_type":"code","source":"#Tokenize the sentences\nfrom string import punctuation\n#convert all revies to lowercase\nx_tr = np.char.lower(x_tr)\nx_val = np.char.lower(x_val)\nx_test = np.char.lower(x_test)\n\n#remove punctuation\nx_tr= [c for c in x_tr if c not in punctuation]\nx_val = [c for c in x_val if c not in punctuation]\nx_test = [c for c in x_test if c not in punctuation]","metadata":{"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\n\n#preparing vocabulary\ntokenizer.fit_on_texts(list(x_tr))\n\n#converting text into integer sequences\nx_tr_seq  = tokenizer.texts_to_sequences(x_tr) \nx_val_seq = tokenizer.texts_to_sequences(x_val)\nx_test_seq = tokenizer.texts_to_sequences(x_test)\n\n\n#padding to prepare sequences of same length\nx_tr_pad  = pad_sequences(x_tr_seq, maxlen=1000)\nx_val_pad = pad_sequences(x_val_seq, maxlen=1000)\nx_test_pad = pad_sequences(x_test_seq,maxlen=1000)","metadata":{"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"We will need the original lengths of each sequence later:","metadata":{}},{"cell_type":"code","source":"#length of the reviews\nseqlen_train = [len(x) for x in x_tr_seq]\nseqlen_val = [len(x) for x in x_val_seq] \nseqlen_test = [len(x) for x in x_test_seq] ","metadata":{"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# this might be an issue \nvocab=len(tokenizer.word_index) + 1 #+1 for padding\nprint(vocab)","metadata":{"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"18828\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating Tensors","metadata":{}},{"cell_type":"markdown","source":"#### Extract input and output tensors","metadata":{}},{"cell_type":"code","source":"# x = torch.tensor(train).to(torch.float64)\n\nX_tr = torch.from_numpy(np.array(list(x_tr_pad)))\nX_train = torch.tensor(X_tr).to(torch.int64)\n\ny_train = torch.LongTensor(y_tr)\nseqlen_train = torch.LongTensor(seqlen_train)\nprint(f\"{X_train.size()},\\n{y_train.size()}\\n{seqlen_train.size() }\\n\")\nprint(\"tensor dimensions\", X_train.dim)\n\nX_v = torch.from_numpy(np.array(list(x_val_pad)))\nX_val = torch.tensor(X_v).to(torch.torch.int64)\n\ny_val = torch.LongTensor(y_val)\nseqlen_val = torch.LongTensor(seqlen_val)\nprint(f\"{X_val.size() },\\n{y_val.size() }\\n{seqlen_val.size() }\\n\")\n\n\nX_t = torch.from_numpy(np.array(list(x_test_pad)))\nX_test = torch.tensor(X_t).to(torch.torch.int64)\n\ny_test = torch.LongTensor(y_test)\nseqlen_test = torch.LongTensor(seqlen_test)\nprint(f\"{X_test.size() },\\n{y_test.size() }\\n{seqlen_test.size() }\")\n","metadata":{"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"torch.Size([1000, 1000]),\ntorch.Size([1000])\ntorch.Size([1000])\n\ntensor dimensions <built-in method dim of Tensor object at 0x7f02d9233c30>\ntorch.Size([200, 1000]),\ntorch.Size([200])\ntorch.Size([200])\n\ntorch.Size([200, 1000]),\ntorch.Size([200])\ntorch.Size([200])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if sys.path[0] == '':\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## The `LSTMClassifier` class\n\nWe now define our own LSTM sequence classifier model.\n\nAll PyTorch modules must subclass `nn.Module` (or one of its subclasses) and call `init` before any attribute assignment.\n\nThere two methods we have to implement:\n- `__init__`: defines submodules. These constitute the nodes _computation graph_.\n- `forward` implements the forward pass of the module. This is how we map the input to the output. The way we pass the input through the module implicitly builds a directed graph of the submodules named _computation graph_.","metadata":{}},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.lstm = nn.LSTM(\n            input_size=embedding_size,\n            hidden_size=hidden_size,\n            num_layers=1,\n            bidirectional=True,\n            batch_first=True,\n        )\n        self.dense = nn.Linear(hidden_size * 2, output_size)\n        \n    # the input signature of forward changes\n    def forward(self, sequences, sequence_lens):\n        embedded = self.embedding(sequences)\n        \n        # THIS IS THE MODIFIED PART\n        # returns a PackedSequence object\n        packed = nn.utils.rnn.pack_padded_sequence(\n            embedded,\n            sequence_lens.clamp(max=1000),\n            enforce_sorted=False,\n            batch_first=True)\n        packed_outputs, (h, c) = self.lstm(packed)\n        # extract LSTM outputs (not used here)\n        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n        \n        h = torch.cat((h[0], h[1]), dim=-1)\n        output = self.dense(h)\n        return output","metadata":{"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"## Instantiating the model","metadata":{}},{"cell_type":"code","source":"input_size = vocab\nembedding_size = 30\nhidden_size = 64\n# number of labels i.e 2\noutput_size = train_data.label.nunique()\n\nmodel = LSTMClassifier(input_size, embedding_size, hidden_size, output_size)\nmodel","metadata":{"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"LSTMClassifier(\n  (embedding): Embedding(18828, 30)\n  (lstm): LSTM(30, 64, batch_first=True, bidirectional=True)\n  (dense): Linear(in_features=128, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Batching","metadata":{}},{"cell_type":"code","source":"class BatchedIterator:\n    def __init__(self, *tensors, batch_size):\n        # all tensors must have the same first dimension\n        assert len(set(len(tensor) for tensor in tensors)) == 1\n        self.tensors = tensors\n        self.batch_size = batch_size\n    \n    def iterate_once(self):\n        num_data = len(self.tensors[0])\n        for start in range(0, num_data, self.batch_size):\n            end = start + self.batch_size\n            yield tuple(tensor[start:end] for tensor in self.tensors)\n            ","metadata":{"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"train_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=16)\n#prints number of batches\nfor X, seqlens, y in train_iter.iterate_once():\n    print(f\"{X.size()  }, {seqlens.size()  }, {y.size() }\")","metadata":{"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"torch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([16, 1000]), torch.Size([16]), torch.Size([16])\ntorch.Size([8, 1000]), torch.Size([8]), torch.Size([8])\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ## Loss function and optimizer\n\nThe **loss function** or **cost function** quantifies cost of the model output differing from the expected target values.\n\nThe optimizer adjusts the model's parameters in accordance with the loss.","metadata":{}},{"cell_type":"code","source":"from torch import optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())","metadata":{"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"## Sanity check on Untrained models\nTrain and val accuracy should be really bad without training.","metadata":{}},{"cell_type":"code","source":"# requires a large memory as we have a large vocab\nlogits = model(X_train, seqlen_train)\ny = logits.argmax(axis=1)\naccuracy = torch.sum(torch.eq(y, y_train)) / y.size(0)\nprint(f\"Train accuracy: {accuracy:.1%}\")","metadata":{"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"Train accuracy: 51.3%\n","output_type":"stream"}]},{"cell_type":"code","source":"logits = model(X_val, seqlen_val)\ny = logits.argmax(axis=1)\naccuracy = torch.sum(torch.eq(y, y_val)) / y.size(0)\nprint(f\"Val accuracy: {accuracy:.1%}\")","metadata":{"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Val accuracy: 47.0%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training\n\n\nWe collect training statistics at the end of each epochs in `metrics`.","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nnum_epochs = 30 \nbatch_size = 128\n\nmetrics = defaultdict(list)\ntrain_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=batch_size)","metadata":{"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"We train the model batch by batch and then evaluate it on the train and the dev data at the end of each epoch.\nSince the dataset is small, we can evaluate it the whole data in one step without batching.\n\nNote that the model should be set to **train** or **eval** mode accordingly. Stochastic steps such as dropout are disabled in **eval** mode.","metadata":{}},{"cell_type":"code","source":"patience = 2\npatience_counter = 0\nprevious_loss = 100\nprevious_accuracy = 0\nfor epoch in range(num_epochs):\n   \n    model.train()\n    # Training loop\n    for X_batch, seqlen_batch, y_batch in train_iter.iterate_once():\n        y_out = model(X_batch, seqlen_batch)\n        loss = criterion(y_out, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    with torch.no_grad():\n        model.eval()  # or model.train(False)\n        # Train and dev loss at the end of the epoch\n        y_out = model(X_train, seqlen_train)\n        train_loss = criterion(y_out, y_train).item()\n        metrics['train_loss'].append(train_loss)\n        labels = y_out.argmax(axis=1)\n        train_accuracy = (torch.eq(y_train, labels).sum() / labels.size(0)).item()\n        metrics['train_accuracy'].append(train_accuracy)\n\n        y_out = model(X_val, seqlen_val)\n        val_loss = criterion(y_out, y_val).item()\n        metrics['val_loss'].append(val_loss)\n        labels = y_out.argmax(axis=1)\n        val_accuracy = (torch.eq(y_val, labels).sum() / labels.size(0)).item()\n        metrics['val_accuracy'].append(val_accuracy)\n        \n        if val_accuracy <= previous_accuracy and val_loss <= previous_loss:\n            patience_counter += 1\n            \n        previous_accuracy = val_accuracy\n        previous_loss = val_loss\n            \n    \n    print(f\"{epoch} -- {train_loss:.3f} - {train_accuracy:.1%} - {val_loss:.3f} - {val_accuracy:.1%}\")\n    \n#     if patience_counter == patience:\n#             break","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0 -- 0.693 - 52.6% - 0.693 - 49.0%\n1 -- 0.692 - 52.7% - 0.695 - 49.0%\n2 -- 0.691 - 52.8% - 0.695 - 49.0%\n3 -- 0.690 - 52.8% - 0.693 - 49.0%\n4 -- 0.690 - 52.7% - 0.693 - 49.0%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation\n\n### Training curves","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 4))\n\nsns.lineplot(data=metrics['train_loss'], ax=ax[0], label='train loss')\nsns.lineplot(data=metrics['val_loss'], ax=ax[0], label='val loss')\n\nsns.lineplot(data=metrics['train_accuracy'], ax=ax[1], label='train acc')\nsns.lineplot(data=metrics['val_accuracy'], ax=ax[1], label='val acc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test accuracy","metadata":{}},{"cell_type":"code","source":"logits = model(X_test, seqlen_test)\ntest_prediction = logits.argmax(axis=1)\ntest_accuracy = torch.sum(torch.eq(test_prediction, y_test)) / y_test.size(0)\nprint(f\"Test accuracy: {test_accuracy:.1%}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}