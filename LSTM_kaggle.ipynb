{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Valid.csv\n/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Train.csv\n/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# train_data = pd.read_csv('')\n# test_data = pd.read_csv('')\n# validation_data = pd.read_csv('')\n# train_data.head()\n\ntrain_data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Valid.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Train.csv\")\nvalidation_data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv\")\n\ntrain_data.head()","metadata":{"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  It's been about 14 years since Sharon Stone aw...      0\n1  someone needed to make a car payment... this i...      0\n2  The Guidelines state that a comment must conta...      0\n3  This movie is a muddled mish-mash of clichés f...      0\n4  Before Stan Laurel became the smaller half of ...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It's been about 14 years since Sharon Stone aw...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>someone needed to make a car payment... this i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Guidelines state that a comment must conta...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This movie is a muddled mish-mash of clichés f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Before Stan Laurel became the smaller half of ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train_data.sample(1000, random_state=1).reset_index(drop=True)\ntest_data = test_data.sample(200, random_state=1).reset_index(drop=True)\nvalidation_data = validation_data.sample(200, random_state=1).reset_index(drop=True)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Barbara Payton is the suppose-to-be sultry sex...      0\n1  \"The Bubble\" is an effort to make a gay Romeo ...      0\n2  This film illustrates the worst part of surviv...      1\n3  The Hospital is a movie that was made ahead of...      1\n4  How powerful and captivating simple quality fi...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Barbara Payton is the suppose-to-be sultry sex...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"The Bubble\" is an effort to make a gay Romeo ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This film illustrates the worst part of surviv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Hospital is a movie that was made ahead of...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How powerful and captivating simple quality fi...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_tr, y_tr = train_data['text'].values.astype(str), train_data['label'].values\nx_val, y_val = validation_data['text'].values.astype(str), validation_data['label'].values\nx_test,y_test = test_data['text'].values.astype(str) , test_data['label'].values\nprint(len(x_tr), len(y_tr))\nprint(len(x_val), len(y_val))\nprint(len(x_test), len(y_test))","metadata":{"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"1000 1000\n200 200\n200 200\n","output_type":"stream"}]},{"cell_type":"code","source":"#Tokenize the sentences\nfrom string import punctuation\n#convert all revies to lowercase\nx_tr = np.char.lower(x_tr)\nx_val = np.char.lower(x_val)\nx_test = np.char.lower(x_test)\n\n#remove punctuation\nx_tr= [c for c in x_tr if c not in punctuation]\nx_val = [c for c in x_val if c not in punctuation]\nx_test = [c for c in x_test if c not in punctuation]","metadata":{"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\n\n#preparing vocabulary\ntokenizer.fit_on_texts(list(x_tr))\n\n#converting text into integer sequences\nx_tr_seq  = tokenizer.texts_to_sequences(x_tr) \nx_val_seq = tokenizer.texts_to_sequences(x_val)\nx_test_seq = tokenizer.texts_to_sequences(x_test)\n\n\n#padding to prepare sequences of same length\nx_tr_pad  = pad_sequences(x_tr_seq, maxlen=1000)\nx_val_pad = pad_sequences(x_val_seq, maxlen=1000)\nx_test_pad = pad_sequences(x_test_seq,maxlen=1000)","metadata":{"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"#length of the reviews\nseqlen_train = [len(x) for x in x_tr_seq]\nseqlen_val = [len(x) for x in x_val_seq] \nseqlen_test = [len(x) for x in x_test_seq] ","metadata":{"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# this might be an issue \nvocab=len(tokenizer.word_index) + 1 #+1 for padding\nprint(vocab)","metadata":{"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"19012\n","output_type":"stream"}]},{"cell_type":"code","source":"# x = torch.tensor(train).to(torch.float64)\n\nX_tr = torch.from_numpy(np.array(list(x_tr_pad)))\nX_train = torch.tensor(X_tr).to(torch.int64)\n\ny_train = torch.LongTensor(y_tr)\nseqlen_train = torch.LongTensor(seqlen_train)\nprint(f\"{X_train.size()},\\n{y_train.size()}\\n{seqlen_train.size() }\\n\")\n\nX_v = torch.from_numpy(np.array(list(x_val_pad)))\nX_val = torch.tensor(X_v).to(torch.torch.int64)\n\ny_val = torch.LongTensor(y_val)\nseqlen_val = torch.LongTensor(seqlen_val)\nprint(f\"{X_val.size() },\\n{y_val.size() }\\n{seqlen_val.size() }\\n\")\n\n\nX_t = torch.from_numpy(np.array(list(x_test_pad)))\nX_test = torch.tensor(X_t).to(torch.torch.int64)\n\ny_test = torch.LongTensor(y_test)\nseqlen_test = torch.LongTensor(seqlen_test)\nprint(f\"{X_test.size() },\\n{y_test.size() }\\n{seqlen_test.size() }\")\n","metadata":{"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"torch.Size([1000, 1000]),\ntorch.Size([1000])\ntorch.Size([1000])\n\ntorch.Size([200, 1000]),\ntorch.Size([200])\ntorch.Size([200])\n\ntorch.Size([200, 1000]),\ntorch.Size([200])\ntorch.Size([200])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  # This is added back by InteractiveShellApp.init_path()\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","output_type":"stream"}]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.lstm = nn.LSTM(\n            input_size=embedding_size,\n            hidden_size=hidden_size,\n            num_layers=1,\n            bidirectional=True,\n            batch_first=True,\n        )\n        self.dense = nn.Linear(hidden_size * 2, output_size)\n        \n    # the input signature of forward changes\n    def forward(self, sequences, sequence_lens):\n        embedded = self.embedding(sequences)\n        \n        # THIS IS THE MODIFIED PART\n        # returns a PackedSequence object\n        packed = nn.utils.rnn.pack_padded_sequence(\n            embedded,\n            sequence_lens,\n            enforce_sorted=False,\n            batch_first=True)\n        packed_outputs, (h, c) = self.lstm(packed)\n        # extract LSTM outputs (not used here)\n        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n        \n        h = torch.cat((h[0], h[1]), dim=-1)\n        output = self.dense(h)\n        return output","metadata":{"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"input_size = vocab\nembedding_size = 30\nhidden_size = 64\n# number of labels i.e 2\noutput_size = train_data.label.nunique()\n\nmodel = LSTMClassifier(input_size, embedding_size, hidden_size, output_size)\nmodel","metadata":{"trusted":true},"execution_count":119,"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"LSTMClassifier(\n  (embedding): Embedding(19012, 30)\n  (lstm): LSTM(30, 64, batch_first=True, bidirectional=True)\n  (dense): Linear(in_features=128, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"class BatchedIterator:\n    def __init__(self, *tensors, batch_size):\n        # all tensors must have the same first dimension\n        assert len(set(len(tensor) for tensor in tensors)) == 1\n        self.tensors = tensors\n        self.batch_size = batch_size\n    \n    def iterate_once(self):\n        num_data = len(self.tensors[0])\n        for start in range(0, num_data, self.batch_size):\n            end = start + self.batch_size\n            yield tuple(tensor[start:end] for tensor in self.tensors)\n            ","metadata":{"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"train_iter = BatchedIterator(X_train, seqlen_train, y_train, batch_size=501)\n#prints number of batches\nfor X, seqlens, y in train_iter.iterate_once():\n    print(f\"{X.size()  }, {seqlens.size()  }, {y.size() }\")","metadata":{"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"torch.Size([501, 1000]), torch.Size([501]), torch.Size([501])\ntorch.Size([499, 1000]), torch.Size([499]), torch.Size([499])\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())","metadata":{"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# requires a large memory as we have a large vocab\nlogits = model(X_train, seqlen_train)\ny = logits.argmax(axis=1)\naccuracy = torch.sum(torch.eq(y, y_train)) / y.size(0)\nprint(f\"Train accuracy: {accuracy:.1%}\")","metadata":{"trusted":true},"execution_count":123,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-123-ea2305dea381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# requires a large memory as we have a large vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train accuracy: {accuracy:.1%}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-118-b7601581dcf2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequences, sequence_lens)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             batch_first=True)\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpacked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# extract LSTM outputs (not used here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlstm_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 585\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: start (231945) + length (4) exceeds dimension size (231945)."],"ename":"RuntimeError","evalue":"start (231945) + length (4) exceeds dimension size (231945).","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}